{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multi Layer Preceptron[Digit Data Scikit].ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zexross/club-assignments/blob/master/multi-layer-preceptron/Multi_Layer_Preceptron%5BDigit_Data_Scikit%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kveKPW-axdHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import struct as st\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_digits"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cPNYV4NxiYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # Initialize the Parameters   \n",
        "def initialize_parameters(layer_dims):\n",
        "    parameters = {}\n",
        "    L = len(layer_dims)            # number of layers in the network\n",
        "\n",
        "    for l in range(1, L):\n",
        "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1])*0.01\n",
        "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
        "        \n",
        "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
        "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
        "        \n",
        "    return parameters    "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8tHAPBLxm8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Activation Funtion\n",
        "def sigmoid(Z):\n",
        "    A=1/(1+np.exp(-Z))\n",
        "    return A\n",
        "\n",
        "def tanh(Z):               # Use of tanh function\n",
        "    A=np.tanh(Z)\n",
        "    return A"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1HtpqHHxn1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Calculation of Z = W*A_previouse + B\n",
        "def linear_forward(A,W,b):\n",
        "    Z=np.dot(W,A)+b\n",
        "    return Z"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBZpE2kzxrAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculation the of the activation Funtion. \n",
        "#        A = Sigmoid(Z) **Need to Update**\n",
        "def linear_activation_forward(A_prev, W, b, activation_type): \n",
        "    \n",
        "    if activation_type == \"Sigmoid\":            #Use of activation funtion in hidden layer is Sigmoid funtion\n",
        "        Z=linear_forward(A_prev,W,b)\n",
        "        A=sigmoid(Z)\n",
        "    elif activation_type == \"tanh\":\n",
        "        Z=linear_forward(A_prev,W,b)\n",
        "        A=tanh(Z)\n",
        "                   \n",
        "    return A,Z  "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWDNwXN3xt1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compute Cost of the overall model.\n",
        "#       Cost = Summation(Loss)/(Number of input data), where Loss= - Y*ln(Activation) - (1-Y)*ln(1 - Activation)\n",
        "def compute_cost(AL,Y):\n",
        "    data_length = Y.shape[1]\n",
        "    cost =(-1/data_length) * np.sum(np.multiply(Y, np.log(AL)) + np.multiply(1 - Y, np.log(1 - AL)))\n",
        "    cost = np.squeeze(cost)\n",
        "    assert(cost.shape == ())  \n",
        "    return cost"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uroZMvxaxwp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Linear_backward\n",
        "def linear_backward(dZ, A):\n",
        "    data_length = A.shape[1]\n",
        "    dW = (1/data_length)*np.dot(dZ,A.T)\n",
        "    db = (1/data_length)*np.sum(dZ, axis=1, keepdims=True)\n",
        "    return dW,db"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1jwuGDtxzjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Linear_activation_backward\n",
        "def linear_activation_backward(A, cache, Layer):\n",
        "    if Layer == \"Output Layer\":\n",
        "        Y, AL = cache\n",
        "        dZ2 = A - Y\n",
        "        dW, db = linear_backward(dZ2, AL)\n",
        "        return dZ2, dW, db\n",
        "    elif Layer == \"Hidden Layer\":\n",
        "        X, W2, dZ2 = cache\n",
        "        dZ1 = np.dot(W2.T,dZ2)*(1-pow(A,2))\n",
        "        dW, db = linear_backward(dZ1, X)\n",
        "        return dZ1,dW, db"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oux9B7qYx3gA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Updates the parameters according to the obtained gradient values\n",
        "def update_parameters(parameters, grads, learning_rate):\n",
        "    \n",
        "    L = len(parameters)//2           # number of layers in the neural network\n",
        "    \n",
        "    for l in range(L):                  # Update rule for each parameter. Use a for loop.\n",
        "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l + 1)] - learning_rate * grads[\"dW\" + str(l + 1)]\n",
        "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l + 1)] - learning_rate * grads[\"db\" + str(l + 1)]    \n",
        "    return parameters"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAeLqGQax87y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Main body of the Nueral Net Model which contains the procedural instructions to the execution of Nueral net model\n",
        "def L_layer_network(X,Y,learningrate,layer_dims,num_iterations,print_cost):\n",
        "    costs=[]\n",
        "    \n",
        "    #Initailise and fetch the weights through dictionary\n",
        "    parameters = initialize_parameters(layer_dims)\n",
        "    L = len(parameters) // 2                           # number of layers in the neural network\n",
        "    activation = {}\n",
        "    linearsum = {}\n",
        "    \n",
        "    for i in range(0, num_iterations):\n",
        "        A = X\n",
        "        # Forward propagation\n",
        "        for l in range(1, L):\n",
        "            A_prev = A\n",
        "            activation['A'+str(l)], linearsum['Z'+str(l)] = linear_activation_forward(A_prev, parameters['W'+str(l)], parameters['b' + str(l)], \"tanh\")   #Calculation of activaion output of hidden layer\n",
        "            A = activation['A'+str(l)]\n",
        "        \n",
        "        activation['A'+str(L)], linearsum['Z'+str(L)] = linear_activation_forward(A, parameters['W'+str(L)], parameters['b' + str(L)], \"Sigmoid\")        #Calculation of activation output of output layer\n",
        "    \n",
        "        # Compute cost\n",
        "        cost = compute_cost(activation['A'+str(L)], Y)\n",
        "        costs.append(cost)\n",
        "        \n",
        "         # Stores the gradient values in the dictionary grads\n",
        "        grads = {}\n",
        "        data_length = Y.shape[1]\n",
        "        \n",
        "        # Backward propagation\n",
        "        activation['A'+str(0)] = X\n",
        "        cache = (Y, activation['A'+str(L-1)])\n",
        "        linearsum['dZ'+str(L)] ,grads['dW'+str(L)], grads['db'+str(L)] = linear_activation_backward(activation['A'+str(L)], cache, \"Output Layer\")\n",
        "        \n",
        "        for l in reversed(range(1,L)):\n",
        "            cache = (activation['A'+str(l-1)], parameters['W'+str(l+1)], linearsum['dZ'+str(l+1)])\n",
        "            linearsum['dZ'+str(l)], grads['dW'+str(l)], grads['db'+str(l)] = linear_activation_backward(activation['A'+str(l)], cache, \"Hidden Layer\")\n",
        "        \n",
        "    \n",
        "        # Update the parameters\n",
        "        parameters =  update_parameters(parameters, grads, learningrate)\n",
        "        \n",
        "        #Vary the learning rate\n",
        "        if(cost > 0.37):\n",
        "            learningrate = learningrate\n",
        "        elif(cost<0.37 and cost>0.2):\n",
        "            learningrate = 0.5\n",
        "        elif(cost<0.25 and cost>0.1):\n",
        "            learningrate = 0.3\n",
        "            \n",
        "        # Print the cost every 100 training example\n",
        "        if print_cost and i % 100 == 0:\n",
        "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
        "    \n",
        "    #Plot the cost funtion curve\n",
        "    plt.plot(costs)\n",
        "    plt.ylabel(\"Cost\")\n",
        "    plt.xlabel(\"iterations\")\n",
        "    plt.show()\n",
        "    return parameters,activation,linearsum"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTEl29m5x-rk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9a202e5-09b2-465b-b161-ad6829f3b4e8"
      },
      "source": [
        "# Input Data(Digit Data Set)\n",
        "\n",
        "digits = load_digits()\n",
        "print(\"Data size:\",digits.data.shape)\n",
        "X = (1/255)*digits.data"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data size: (1797, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhWn6buTyEHD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "d4349b11-4da4-467c-d886-e75afa8632c2"
      },
      "source": [
        "layer_dims = [np.squeeze(np.shape(X[0])),20,10]\n",
        "learningrate = 1\n",
        "print_cost=True\n",
        "\n",
        "#Label Data(Digit Data Set)\n",
        "label_array = digits.target\n",
        "\n",
        "print(\"Size images_array : \",len(label_array))\n",
        "\n",
        "Y=np.zeros((len(label_array),10))\n",
        "for i in range (0,len(label_array)):\n",
        "    for j in range (0,10):\n",
        "        if label_array[i]==j:\n",
        "            Y[i][j] = 1\n",
        "        else:\n",
        "            Y[i][j] = 0\n",
        "\n",
        "parameters,activation,linearsum = L_layer_network(X.T, Y.T, learningrate, layer_dims, 1000, print_cost)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size images_array :  1797\n",
            "Cost after iteration 0: 6.931508162210922\n",
            "Cost after iteration 100: 3.2502415683158214\n",
            "Cost after iteration 200: 3.2454574231094253\n",
            "Cost after iteration 300: 3.1836115062839276\n",
            "Cost after iteration 400: 2.6947164028044743\n",
            "Cost after iteration 500: 2.7653173629530534\n",
            "Cost after iteration 600: 2.252185541023886\n",
            "Cost after iteration 700: 1.658391041672186\n",
            "Cost after iteration 800: 1.4467439591464164\n",
            "Cost after iteration 900: 1.3290130574607975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkXRMHlUyODc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Decodes the output that the trained model predicts on the testing set\n",
        "def Output(A2):\n",
        "    key = A2[0][0]\n",
        "    p = 0\n",
        "    for i in range (0,10):\n",
        "        if A2[i][0]>=key:\n",
        "                p = i\n",
        "                key = A2[i][0]\n",
        "    return p"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDg1RHKCyb40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculates the accuracy the trained model is able to achieve\n",
        "def accuracy_predictor(out, label_array):\n",
        "    fav = 0\n",
        "    for i in range(0,51):\n",
        "        if(out[i]==label_array[i]):\n",
        "            fav = fav + 1\n",
        "    accuracy = fav/51*100\n",
        "    return accuracy"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJXw_9ruyh3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def modeltest(X,parameters,activation,linearsum,out):\n",
        "    L = len(parameters) // 2 \n",
        "    A = X\n",
        "    for l in range(1, L):\n",
        "            A_prev = A\n",
        "            activation['A'+str(l)], linearsum['Z'+str(l)] = linear_activation_forward(A_prev, parameters['W'+str(l)], parameters['b' + str(l)], \"tanh\")   #Calculation of activaion output of hidden layer\n",
        "            A = activation['A'+str(l)]\n",
        "        \n",
        "    activation['A'+str(L)], linearsum['Z'+str(L)] = linear_activation_forward(A, parameters['W'+str(L)], parameters['b' + str(L)], \"Sigmoid\")        #Calculation of activation output of output layer\n",
        "    \n",
        "    A = Output(activation['A'+str(L)])\n",
        "    out.append(A)\n",
        "    return out"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc4FBgvMymNv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b6cf2f04-32c8-48b9-e5ac-c9ecb5d216e7"
      },
      "source": [
        "Train_X=np.zeros(shape=(64,1))\n",
        "out = []\n",
        "for j in range(0,len(label_array[:51])):\n",
        "    for i in range(0,64):\n",
        "        Train_X[i][0] = X[j][i]\n",
        "    out = modeltest(Train_X, parameters,activation,linearsum, out)\n",
        "    \n",
        "accuracy = accuracy_predictor(out,label_array[:51])    \n",
        "print(\"A :\",out, end=\" \")\n",
        "print(\"\\n\\naccuracy = \", accuracy, end=\"%\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A : [0, 1, 1, 3, 4, 9, 6, 7, 8, 9, 0, 1, 1, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 9, 8, 9, 0, 9, 5, 5, 6, 5, 0, 5, 5, 9, 8, 4, 1, 7, 7, 3, 5, 1, 0, 0, 8] \n",
            "\n",
            "accuracy =  86.27450980392157%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzkXY_TFX-ZJ",
        "colab_type": "text"
      },
      "source": [
        "## End Note\n",
        "\n",
        "---\n",
        "Now create your own changes to optimise the model. Best of luck!!\n"
      ]
    }
  ]
}